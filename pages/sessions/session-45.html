<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sesi 45: Deep Learning dengan TensorFlow - Cendiks</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="../css/styles.css">
    <script src="../js/scripts.js"></script>
</head>
<body class="bg-gray-50 text-gray-800 font-sans">
    <!-- Header -->
    <header class="bg-white shadow-md">
        <div class="container mx-auto px-4 py-4 flex justify-between items-center">
            <button onclick="history.back()" class="text-gray-600 hover:text-primary mr-4">‚Üê Kembali</button>
            <h1 class="text-2xl font-bold text-primary">Cendiks</h1>
            <nav class="space-x-4">
                <a href="../index.html" class="text-gray-600 hover:text-primary">Beranda</a>
                <a href="sessions.html" class="text-gray-600 hover:text-primary">Sesi Pembelajaran</a>
                <a href="install.html" class="text-gray-600 hover:text-primary">Instalasi Python</a>
                <a href="certification.html" class="text-gray-600 hover:text-primary">Ujian Sertifikasi</a>
                <a href="more.html" class="text-gray-600 hover:text-primary">More</a>
            </nav>
        </div>
    </header>

    <!-- Hero Section -->
    <section class="bg-gradient-to-r from-blue-100 to-yellow-100 py-20">
        <div class="container mx-auto px-4 text-center">
            <h2 class="text-4xl font-bold mb-4 text-gray-800 fade-in-up">üìö Sesi 45: Deep Learning dengan TensorFlow</h2>
            <p class="text-xl mb-8 text-gray-600 slide-in-right">Pelajari neural networks dan deep learning menggunakan TensorFlow</p>
        </div>
    </section>

    <!-- Content Section -->
    <section class="py-16">
        <div class="container mx-auto px-4 max-w-4xl">
            <div class="bg-white p-8 rounded-lg shadow-md">
                <h3 class="text-2xl font-bold mb-6">Materi Pembelajaran</h3>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">1Ô∏è‚É£ Pengenalan Deep Learning</h4>
                    <p class="text-gray-600 mb-4">Memahami konsep dasar neural networks dan deep learning.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code># Deep Learning adalah subbidang Machine Learning
# yang menggunakan neural networks dengan banyak layer

# Instalasi TensorFlow
# pip install tensorflow

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

print("TensorFlow version:", tf.__version__)

# Konsep Dasar Neural Network:
# - Neuron: Unit komputasi dasar
# - Layer: Kumpulan neuron
# - Weight: Parameter yang dipelajari
# - Bias: Offset untuk setiap neuron
# - Activation Function: Fungsi non-linear

# Contoh struktur neural network sederhana:
# Input Layer (784 neurons untuk MNIST) -> Hidden Layer (128 neurons) -> Output Layer (10 neurons)

# Arsitektur Deep Learning:
# 1. Feedforward Neural Networks (FNN)
# 2. Convolutional Neural Networks (CNN) - untuk gambar
# 3. Recurrent Neural Networks (RNN) - untuk sequence
# 4. Transformer - untuk NLP

# Keunggulan Deep Learning:
# - Automatic feature extraction
# - High accuracy untuk data kompleks
# - Scalable untuk big data
# - End-to-end learning

# Tantangan:
# - Membutuhkan banyak data
# - Komputasi intensif
# - Sulit diinterpretasikan (black box)
# - Overfitting risk

print("\nDeep Learning Applications:")
print("- Computer Vision: Image classification, object detection")
print("- Natural Language Processing: Translation, sentiment analysis")
print("- Speech Recognition: Voice assistants")
print("- Recommendation Systems: Netflix, Amazon")
print("- Medical Diagnosis: Cancer detection")
print("- Autonomous Vehicles: Self-driving cars")</code></pre>
                    </div>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">2Ô∏è‚É£ TensorFlow Fundamentals</h4>
                    <p class="text-gray-600 mb-4">Dasar-dasar TensorFlow dan tensor operations.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code>import tensorflow as tf
import numpy as np

print("=== TensorFlow Fundamentals ===")

# 1. Tensors - struktur data dasar di TensorFlow
print("\n1. Tensors:")

# Scalar (0D tensor)
scalar = tf.constant(5)
print(f"Scalar: {scalar}")
print(f"Shape: {scalar.shape}")
print(f"Rank: {scalar.ndim}")

# Vector (1D tensor)
vector = tf.constant([1, 2, 3, 4, 5])
print(f"\nVector: {vector}")
print(f"Shape: {vector.shape}")
print(f"Rank: {vector.ndim}")

# Matrix (2D tensor)
matrix = tf.constant([[1, 2, 3], [4, 5, 6]])
print(f"\nMatrix: {matrix}")
print(f"Shape: {matrix.shape}")
print(f"Rank: {matrix.ndim}")

# 3D tensor
tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])
print(f"\n3D Tensor: {tensor_3d}")
print(f"Shape: {tensor_3d.shape}")
print(f"Rank: {tensor_3d.ndim}")

# 2. Tensor Operations
print("\n2. Tensor Operations:")

a = tf.constant([[1, 2], [3, 4]])
b = tf.constant([[5, 6], [7, 8]])

print(f"a + b = {a + b}")
print(f"a * b = {a * b}")  # Element-wise multiplication
print(f"tf.matmul(a, b) = {tf.matmul(a, b)}")  # Matrix multiplication

# 3. Variables (trainable tensors)
print("\n3. Variables:")
variable = tf.Variable([[1, 2], [3, 4]])
print(f"Variable: {variable}")
print(f"Is trainable: {variable.trainable}")

# Update variable
variable.assign([[5, 6], [7, 8]])
print(f"Updated variable: {variable}")

# 4. Automatic Differentiation
print("\n4. Automatic Differentiation:")

x = tf.Variable(3.0)

with tf.GradientTape() as tape:
    y = x**2

dy_dx = tape.gradient(y, x)
print(f"dy/dx at x=3: {dy_dx}")

# 5. Common TensorFlow operations
print("\n5. Common Operations:")

# Reshaping
tensor = tf.constant([[1, 2, 3], [4, 5, 6]])
reshaped = tf.reshape(tensor, [6])
print(f"Original shape: {tensor.shape}")
print(f"Reshaped: {reshaped}")
print(f"New shape: {reshaped.shape}")

# Slicing
sliced = tensor[:, 1]  # Second column
print(f"Sliced tensor: {sliced}")

# Concatenation
concatenated = tf.concat([tensor, tensor], axis=0)  # Concatenate along rows
print(f"Concatenated shape: {concatenated.shape}")

# Reduction operations
sum_all = tf.reduce_sum(tensor)
mean_all = tf.reduce_mean(tf.cast(tensor, tf.float32))
max_val = tf.reduce_max(tensor)
print(f"Sum: {sum_all}, Mean: {mean_all}, Max: {max_val}")</code></pre>
                    </div>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">3Ô∏è‚É£ Membangun Neural Network Sederhana</h4>
                    <p class="text-gray-600 mb-4">Implementasi feedforward neural network untuk klasifikasi.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code>import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

print("=== Building Simple Neural Network ===")

# 1. Generate synthetic dataset
print("\n1. Dataset Preparation:")
X, y = make_classification(
    n_samples=1000,
    n_features=20,
    n_informative=10,
    n_redundant=10,
    n_classes=2,
    random_state=42
)

print(f"Dataset shape: {X.shape}")
print(f"Number of classes: {len(np.unique(y))}")

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"Training set: {X_train_scaled.shape}")
print(f"Test set: {X_test_scaled.shape}")

# 2. Build Neural Network Model
print("\n2. Building Neural Network:")

model = tf.keras.Sequential([
    # Input layer + First hidden layer
    tf.keras.layers.Dense(64, activation='relu', input_shape=(20,)),
    # Second hidden layer
    tf.keras.layers.Dense(32, activation='relu'),
    # Third hidden layer
    tf.keras.layers.Dense(16, activation='relu'),
    # Output layer (binary classification)
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Display model summary
model.summary()

# 3. Compile Model
print("\n3. Compiling Model:")
model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)

# 4. Train Model
print("\n4. Training Model:")
history = model.fit(
    X_train_scaled, y_train,
    epochs=50,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)

# 5. Evaluate Model
print("\n5. Model Evaluation:")
test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# 6. Make Predictions
print("\n6. Making Predictions:")
predictions = model.predict(X_test_scaled[:5])
predicted_classes = (predictions > 0.5).astype(int).flatten()

print("First 5 predictions:")
for i, (pred, actual) in enumerate(zip(predicted_classes, y_test[:5])):
    print(f"Sample {i+1}: Predicted={pred}, Actual={actual}")

# 7. Visualize Training History
print("\n7. Training Visualization:")

plt.figure(figsize=(12, 4))

# Plot accuracy
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# 8. Save and Load Model
print("\n8. Saving Model:")
model.save('simple_nn_model.h5')
print("Model saved as 'simple_nn_model.h5'")

# Load model (demonstration)
# loaded_model = tf.keras.models.load_model('simple_nn_model.h5')
# print("Model loaded successfully")</code></pre>
                    </div>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">4Ô∏è‚É£ Convolutional Neural Networks (CNN)</h4>
                    <p class="text-gray-600 mb-4">Arsitektur khusus untuk processing gambar.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code>import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical

print("=== Convolutional Neural Networks ===")

# 1. Load MNIST dataset
print("\n1. Loading MNIST Dataset:")
(X_train, y_train), (X_test, y_test) = mnist.load_data()

print(f"Training data shape: {X_train.shape}")
print(f"Test data shape: {X_test.shape}")
print(f"Number of classes: {len(np.unique(y_train))}")

# 2. Preprocess data
print("\n2. Data Preprocessing:")

# Reshape for CNN input (add channel dimension)
X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)
X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)

# Normalize pixel values
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0

# Convert labels to one-hot encoding
y_train_cat = to_categorical(y_train, 10)
y_test_cat = to_categorical(y_test, 10)

print(f"Reshaped training data: {X_train.shape}")
print(f"One-hot encoded labels shape: {y_train_cat.shape}")

# 3. Build CNN Model
print("\n3. Building CNN Model:")

model = tf.keras.Sequential([
    # Convolutional layers
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),

    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),

    # Flatten for dense layers
    tf.keras.layers.Flatten(),

    # Dense layers
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.5),  # Prevent overfitting

    # Output layer
    tf.keras.layers.Dense(10, activation='softmax')
])

model.summary()

# 4. Compile and Train
print("\n4. Training CNN:")
model.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Use smaller dataset for faster training (optional)
X_train_small = X_train[:10000]
y_train_small = y_train_cat[:10000]

history = model.fit(
    X_train_small, y_train_small,
    epochs=10,
    batch_size=64,
    validation_split=0.2,
    verbose=1
)

# 5. Evaluate
print("\n5. Evaluation:")
test_loss, test_accuracy = model.evaluate(X_test, y_test_cat, verbose=0)
print(f"Test Loss: {test_loss:.4f}")
print(f"Test Accuracy: {test_accuracy:.4f}")

# 6. Visualize Results
print("\n6. Visualizing Results:")

# Plot training history
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('CNN Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(1, 2
