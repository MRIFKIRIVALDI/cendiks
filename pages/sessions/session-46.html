<!DOCTYPE html>
<html lang="id">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sesi 46: Natural Language Processing dengan Transformers - Cendiks</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="../css/styles.css">
    <script src="../js/scripts.js"></script>
</head>
<body class="bg-gray-50 text-gray-800 font-sans">
    <!-- Header -->
    <header class="bg-white shadow-md">
        <div class="container mx-auto px-4 py-4 flex justify-between items-center">
            <button onclick="history.back()" class="text-gray-600 hover:text-primary mr-4">‚Üê Kembali</button>
            <h1 class="text-2xl font-bold text-primary">Cendiks</h1>
            <nav class="space-x-4">
                <a href="../index.html" class="text-gray-600 hover:text-primary">Beranda</a>
                <a href="sessions.html" class="text-gray-600 hover:text-primary">Sesi Pembelajaran</a>
                <a href="install.html" class="text-gray-600 hover:text-primary">Instalasi Python</a>
                <a href="certification.html" class="text-gray-600 hover:text-primary">Ujian Sertifikasi</a>
                <a href="more.html" class="text-gray-600 hover:text-primary">More</a>
            </nav>
        </div>
    </header>

    <!-- Hero Section -->
    <section class="bg-gradient-to-r from-blue-100 to-yellow-100 py-20">
        <div class="container mx-auto px-4 text-center">
            <h2 class="text-4xl font-bold mb-4 text-gray-800 fade-in-up">üìö Sesi 46: Natural Language Processing dengan Transformers</h2>
            <p class="text-xl mb-8 text-gray-600 slide-in-right">Pelajari pemrosesan bahasa alami menggunakan arsitektur Transformer</p>
        </div>
    </section>

    <!-- Content Section -->
    <section class="py-16">
        <div class="container mx-auto px-4 max-w-4xl">
            <div class="bg-white p-8 rounded-lg shadow-md">
                <h3 class="text-2xl font-bold mb-6">Materi Pembelajaran</h3>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">1Ô∏è‚É£ Pengenalan Natural Language Processing</h4>
                    <p class="text-gray-600 mb-4">Memahami konsep dasar NLP dan evolusi dari RNN ke Transformers.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code># Natural Language Processing (NLP) adalah bidang AI
# yang fokus pada interaksi antara komputer dan bahasa manusia

# Instalasi libraries NLP
# pip install transformers torch sentence-transformers

import torch
import numpy as np
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import warnings
warnings.filterwarnings('ignore')

print("=== Natural Language Processing ===")

# Evolusi NLP:
# 1. Rule-based systems (regex, grammar rules)
# 2. Statistical methods (n-grams, TF-IDF)
# 3. Neural Networks (Word2Vec, RNN, LSTM)
# 4. Attention Mechanism (Transformer architecture)
# 5. Pre-trained Language Models (BERT, GPT, T5)

# Komponen utama NLP:
# - Tokenization: Memecah teks menjadi unit-unit kecil
# - Part-of-Speech Tagging: Menentukan jenis kata
# - Named Entity Recognition: Mengidentifikasi entitas
# - Sentiment Analysis: Analisis sentimen
# - Machine Translation: Terjemahan otomatis
# - Text Generation: Pembuatan teks
# - Question Answering: Menjawab pertanyaan

print("\nNLP Applications:")
print("- Chatbots dan Virtual Assistants")
print("- Machine Translation (Google Translate)")
print("- Sentiment Analysis (Social media monitoring)")
print("- Text Summarization")
print("- Speech Recognition")
print("- Content Classification")
print("- Information Retrieval")

# Tantangan NLP:
# - Ambiguity: Kata dengan banyak makna
# - Context dependency: Makna tergantung konteks
# - Sarcasm dan irony: Sulit dideteksi
# - Multilingual processing: Berbagai bahasa
# - Computational complexity: Model besar membutuhkan resource banyak

print("\nTransformer Architecture Advantages:")
print("- Parallel processing (vs sequential RNN)")
print("- Long-range dependencies capture")
print("- Self-attention mechanism")
print("- Scalable pre-training")
print("- Transfer learning capabilities")</code></pre>
                    </div>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">2Ô∏è‚É£ Text Preprocessing dan Tokenization</h4>
                    <p class="text-gray-600 mb-4">Persiapan data teks untuk model NLP.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code>import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import string

# Download NLTK resources (run once)
# nltk.download('punkt')
# nltk.download('stopwords')
# nltk.download('wordnet')

print("=== Text Preprocessing ===")

# Sample text
text = """
Natural Language Processing (NLP) adalah cabang dari Artificial Intelligence
yang berfokus pada interaksi antara komputer dan bahasa manusia.
NLP memungkinkan komputer untuk memahami, menginterpretasi, dan menghasilkan
bahasa manusia secara alami. Teknologi ini telah berkembang pesat dengan
adanya deep learning dan transformer architecture.
"""

print("Original text:")
print(text)

# 1. Text Cleaning
print("\n1. Text Cleaning:")

def clean_text(text):
    # Convert to lowercase
    text = text.lower()

    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))

    # Remove numbers
    text = re.sub(r'\d+', '', text)

    # Remove extra whitespace
    text = ' '.join(text.split())

    return text

cleaned_text = clean_text(text)
print("Cleaned text:")
print(cleaned_text)

# 2. Tokenization
print("\n2. Tokenization:")

# Word tokenization
try:
    tokens = word_tokenize(cleaned_text)
    print(f"Word tokens: {tokens[:10]}...")  # Show first 10 tokens
    print(f"Number of tokens: {len(tokens)}")
except:
    # Fallback tokenization if NLTK not available
    tokens = cleaned_text.split()
    print(f"Simple word tokens: {tokens[:10]}...")
    print(f"Number of tokens: {len(tokens)}")

# Sentence tokenization
sentences = text.strip().split('\n')
sentences = [s.strip() for s in sentences if s.strip()]
print(f"\nSentences: {len(sentences)}")
for i, sentence in enumerate(sentences, 1):
    print(f"Sentence {i}: {sentence}")

# 3. Stop Words Removal
print("\n3. Stop Words Removal:")

try:
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word not in stop_words]
    print(f"Original tokens: {len(tokens)}")
    print(f"After stop words removal: {len(filtered_tokens)}")
    print(f"Removed {len(tokens) - len(filtered_tokens)} stop words")
    print(f"Filtered tokens: {filtered_tokens[:10]}...")
except:
    print("NLTK stopwords not available, skipping stop words removal")
    filtered_tokens = tokens

# 4. Lemmatization
print("\n4. Lemmatization:")

try:
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]
    print("Lemmatized tokens:")
    print(f"Original: {filtered_tokens[:5]}")
    print(f"Lemmatized: {lemmatized_tokens[:5]}")
except:
    print("NLTK lemmatizer not available, skipping lemmatization")
    lemmatized_tokens = filtered_tokens

# 5. Using Transformers Tokenizer
print("\n5. Transformers Tokenizer:")

try:
    from transformers import AutoTokenizer

    # Load pre-trained tokenizer
    tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')

    # Tokenize text
    encoded = tokenizer(text, padding=True, truncation=True, return_tensors="pt")

    print(f"Input text: {text[:50]}...")
    print(f"Token IDs: {encoded['input_ids'].tolist()[0][:10]}...")
    print(f"Attention mask: {encoded['attention_mask'].tolist()[0][:10]}...")

    # Decode back to text
    decoded = tokenizer.decode(encoded['input_ids'][0])
    print(f"Decoded text: {decoded[:100]}...")

except ImportError:
    print("Transformers library not available")
except Exception as e:
    print(f"Error with transformers tokenizer: {e}")

# 6. N-grams
print("\n6. N-grams:")

def generate_ngrams(tokens, n):
    """Generate n-grams from tokens"""
    ngrams = []
    for i in range(len(tokens) - n + 1):
        ngrams.append(' '.join(tokens[i:i+n]))
    return ngrams

# Generate bigrams and trigrams
bigrams = generate_ngrams(lemmatized_tokens, 2)
trigrams = generate_ngrams(lemmatized_tokens, 3)

print(f"Bigrams: {bigrams[:5]}")
print(f"Trigrams: {trigrams[:3]}")

print("\n=== Text Preprocessing Complete ===")
print("Preprocessed text is ready for model input!")</code></pre>
                    </div>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">3Ô∏è‚É£ Sentiment Analysis dengan BERT</h4>
                    <p class="text-gray-600 mb-4">Implementasi analisis sentimen menggunakan model BERT.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code>import torch
import numpy as np
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import warnings
warnings.filterwarnings('ignore')

print("=== Sentiment Analysis with BERT ===")

# Sample texts for analysis
texts = [
    "I love this product! It's amazing and works perfectly.",
    "This is the worst purchase I've ever made. Complete waste of money.",
    "The item is okay, nothing special but does the job.",
    "Absolutely fantastic! Highly recommend to everyone.",
    "Terrible quality. Broke after one day. Don't buy!",
    "Great customer service and fast delivery. Very satisfied.",
    "Not worth the price. Overrated and disappointing.",
    "Excellent value for money. Better than expected!"
]

print("Sample texts for sentiment analysis:")
for i, text in enumerate(texts, 1):
    print(f"{i}. {text}")

try:
    # 1. Using Pre-trained Sentiment Analysis Pipeline
    print("\n1. Using Hugging Face Pipeline:")

    # Load sentiment analysis pipeline
    sentiment_pipeline = pipeline(
        "sentiment-analysis",
        model="cardiffnlp/twitter-roberta-base-sentiment-latest",
        tokenizer="cardiffnlp/twitter-roberta-base-sentiment-latest"
    )

    print("Analyzing sentiments...")

    results = []
    for text in texts:
        result = sentiment_pipeline(text)[0]
        results.append({
            'text': text,
            'label': result['label'],
            'confidence': result['score']
        })

    print("\nResults:")
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['label']} ({result['confidence']:.3f})")
        print(f"   Text: {result['text'][:60]}...")

    # 2. Manual Implementation with BERT
    print("\n2. Manual BERT Implementation:")

    # Load pre-trained BERT model and tokenizer
    model_name = "bert-base-uncased"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=2  # Binary classification: positive/negative
    )

    print(f"Model: {model_name}")
    print(f"Number of parameters: {sum(p.numel() for p in model.parameters()):,}")

    # Note: In practice, you'd fine-tune this model on sentiment data
    # This is just a demonstration of the architecture

    # Tokenize sample text
    sample_text = "I absolutely love this amazing product!"
    inputs = tokenizer(sample_text, return_tensors="pt", padding=True, truncation=True)

    print(f"\nSample text: {sample_text}")
    print(f"Tokenized input: {inputs['input_ids']}")
    print(f"Attention mask: {inputs['attention_mask']}")

    # Forward pass (without training)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=1)

    print(f"Logits: {logits}")
    print(f"Probabilities: {probabilities}")

    # 3. Custom Sentiment Analysis Function
    print("\n3. Custom Sentiment Analysis Function:")

    def analyze_sentiment(text, pipeline_model):
        """Analyze sentiment of a given text"""
        result = pipeline_model(text)[0]

        # Convert labels to more readable format
        label_map = {
            'LABEL_0': 'Negative',
            'LABEL_1': 'Neutral',
            'LABEL_2': 'Positive'
        }

        sentiment = label_map.get(result['label'], result['label'])
        confidence = result['score']

        return {
            'text': text,
            'sentiment': sentiment,
            'confidence': confidence
        }

    # Analyze custom text
    custom_texts = [
        "This movie is fantastic! I enjoyed every minute of it.",
        "The food was terrible and the service was slow.",
        "It's an average product, neither good nor bad."
    ]

    print("Custom sentiment analysis:")
    for text in custom_texts:
        result = analyze_sentiment(text, sentiment_pipeline)
        print(f"Text: {result['text']}")
        print(f"Sentiment: {result['sentiment']} (confidence: {result['confidence']:.3f})")
        print()

except ImportError as e:
    print(f"Import error: {e}")
    print("Please install required packages:")
    print("pip install transformers torch")

except Exception as e:
    print(f"Error: {e}")
    print("Note: This example requires internet connection to download models")

print("\n=== Sentiment Analysis Complete ===")</code></pre>
                    </div>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">4Ô∏è‚É£ Text Generation dengan GPT</h4>
                    <p class="text-gray-600 mb-4">Membuat model text generation menggunakan GPT-like architecture.</p>
                    <div class="bg-gray-100 p-4 rounded-lg mb-4">
                        <pre><code>import torch
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM
import warnings
warnings.filterwarnings('ignore')

print("=== Text Generation with GPT ===")

try:
    # 1. Using Pre-trained GPT Model
    print("1. Using GPT-2 for Text Generation:")

    # Load text generation pipeline
    generator = pipeline(
        'text-generation',
        model='gpt2',
        tokenizer='gpt2'
    )

    # Prompts for generation
    prompts = [
        "The future of artificial intelligence",
        "In a world where robots",
        "The most important thing about programming is",
        "Climate change will affect"
    ]

    print("Generating text from prompts...")

    for prompt in prompts:
        print(f"\nPrompt: '{prompt}'")

        # Generate text
        generated = generator(
            prompt,
            max_length=50,
            num_return_sequences=1,
            temperature=0.7,
            do_sample=True,
            pad_token_id=generator.tokenizer.eos_token_id
        )[0]['generated_text']

        print(f"Generated: {generated}")
        print("-" * 50)

    # 2. Manual Implementation with GPT-2
    print("\n2. Manual GPT-2 Implementation:")

    # Load model and tokenizer
    model_name = "gpt2"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)

    # Set pad token
    tokenizer.pad_token = tokenizer.eos_token

    print(f"Model: {model_name}")
    print(f"Vocabulary size: {tokenizer.vocab_size}")
    print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")

    # 3. Custom Text Generation Function
    print("\n3. Custom Text Generation:")

    def generate_text(prompt, max_length=50, temperature=0.7, top_k=50):
        """Generate text from a prompt using GPT-2"""

        # Tokenize input
        inputs = tokenizer(prompt, return_tensors="pt")

        # Generate text
        with torch.no_grad():
            outputs = model.generate(
                inputs['input_ids'],
                max_length=max_length,
                temperature=temperature,
                top_k=top_k,
                do_sample=True,
                num_return_sequences=1,
                pad_token_id=tokenizer.eos_token_id
            )

        # Decode generated text
        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

        return generated_text

    # Test custom generation
    test_prompts = [
        "Machine learning is",
        "The best way to learn Python is",
        "In the year 2050,"
    ]

    print("Custom text generation:")
    for prompt in test_prompts:
        generated = generate_text(prompt, max_length=30)
        print(f"Prompt: {prompt}")
        print(f"Generated: {generated}")
        print()

    # 4. Controlling Generation Parameters
    print("4. Controlling Generation Parameters:")

    prompt = "The benefits of exercise include"

    # Different temperature settings
    temperatures = [0.1, 0.7, 1.5]

    for temp in temperatures:
        generated = generate_text(prompt, temperature=temp, max_length=40)
        print(f"Temperature {temp}: {generated}")

    print()

    # 5. Text Completion Task
    print("5. Text Completion Example:")

    incomplete_texts = [
        "The capital of France is",
        "Python is a programming language that is",
        "The largest planet in our solar system is"
    ]

    print("Completing sentences:")
    for text in incomplete_texts:
        completion = generate_text(text, max_length=len(tokenizer.encode(text)) + 10)
        print(f"Original: {text}")
        print(f"Completed: {completion}")
        print()

except ImportError as e:
    print(f"Import error: {e}")
    print("Please install required packages:")
    print("pip install transformers torch")

except Exception as e:
    print(f"Error: {e}")
    print("Note: This example requires internet connection to download models")

print("\n=== Text Generation Complete ===")
print("Key takeaways:")
print("- GPT models can generate coherent text")
print("- Temperature controls creativity vs predictability")
print("- Top-k sampling helps control output diversity")
print("- Models should be used responsibly")</code></pre>
                    </div>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">5Ô∏è‚É£ Latihan Praktis</h4>
                    <p class="text-gray-600 mb-4">Implementasi NLP pipeline lengkap.</p>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">6Ô∏è‚É£ Video Tutorial</h4>
                    <iframe width="100%" height="315" src="https://www.youtube.com/embed/SZorAJ4I-sA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen class="rounded-lg"></iframe>
                </div>

                <div class="mb-8">
                    <h4 class="text-xl font-semibold mb-4">7Ô∏è‚É£ Kuis Interaktif</h4>
                    <div class="space-y-4">
                        <div>
                            <p class="font-medium mb-2">1. Apa keunggulan utama Transformer dibandingkan RNN?</p>
                            <div class="space-y-2">
                                <label class="flex items-center">
                                    <input type="radio" name="q1" value="a" class="mr-2">
                                    <span>Parallel processing dan long-range dependencies</span>
                                </label>
                                <label class="flex items-center">
                                    <input type="radio" name="q1" value="b" class="mr-2">
                                    <span>Hanya lebih cepat training</span>
                                </label>
                                <label class="flex items-center">
                                    <input type="radio" name="q1" value="c" class="mr-2">
                                    <span>Tidak membutuhkan attention mechanism</span>
                                </label>
                            </div>
                        </div>
                        <div>
                            <p class="font-medium mb-2">2. Apa itu tokenization dalam NLP?</p>
                            <div class="space-y-2">
                                <label class="flex items-center">
                                    <input type="radio" name="q2" value="a" class="mr-2">
                                    <span>Memecah teks menjadi unit-unit kecil</span>
                                </label>
                                <label class="flex items-center">
                                    <input type="radio" name="q2" value="b" class="mr-2">
                                    <span>Menghitung frekuensi kata</span>
                                </label>
                                <label class="flex items-center">
                                    <input type="radio" name="q2" value="c" class="mr-2">
                                    <span>Menerjemahkan bahasa</span>
                                </label>
                            </div>
                        </div>
                        <button onclick="checkQuiz()" class="bg-primary text-white px-6 py-2 rounded-lg hover:bg-blue-700 transition duration-300">Periksa Jawaban</button>
                        <div id="quiz-result" class="mt-4"></div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-gray-800 text-white py-8">
        <div class="container mx-auto px-4 text-center">
            <p>&copy; 2023 Cendiks. Platform belajar Python untuk semua.</p>
        </div>
    </footer>
</body>
</html>
